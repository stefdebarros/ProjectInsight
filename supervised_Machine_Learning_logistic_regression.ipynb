{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID19 severe (hospitalized) cases in Brazil: ML logistic regression\n",
    "\n",
    "Here, publicly available data for hospitalized cases in Brazil is used to perform a retrospective cross-sectional observational study.\n",
    "\n",
    "It means that I want to infer the paramaters driving the outcome from data gathered from hospitals.\n",
    "The data has been downloaded, selected and preprocessed before the steps described in this notebook.\n",
    "\n",
    "The aim is to compare different variants and infer what parameters are driving the severity and the outcome. This will provide answers to the following questions:\n",
    "<ol>\n",
    "    <li> Can we predict the outcome?</li>\n",
    "    <li> If yes, what are the parameters influencing the outcome?</li>\n",
    "</ol>\n",
    "<br>\n",
    "I study only the main outcome: cured/death.\n",
    "\n",
    "This is applied to four different periods of time when four different variants where dominant (>=80% of samples analyzed were corresponding to the variant of interest, source: GISAID database):\n",
    "- Delta\n",
    "- Omicron BA.1\n",
    "- Omicron BA.2\n",
    "- Omicron BA.4/BA.5\n",
    "\n",
    "Specifically, in this notebook, **I show the results of Machine Learning logistic regression on the main outcome**.\n",
    "\n",
    "> **Data source**: all the data has been taken from the Brazilian Ministry of Health https://opendatasus.saude.gov.br/organization/ministerio-da-saude\n",
    ">\n",
    ">It requires translation from Portuguese to English\n",
    "\n",
    "> **<font size=5 color='red'>IMPORTANT DISCLAIMER</font>**: in this work, we extract data about **HOSPITALIZED** patients, by definition people already severely affected by the disease, hence a strongly biased sample unfit to get the whole picture about all the aspects of COVID19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comorb_list = ['cardiovascular_disease','hematologic_disease','down_syndrom','liver_disease','comorb_asthma','diabetes',\n",
    "               'neurological_disease','chronic_lung_disease','weaken_immune_system','renal_disease','obesity','puerperal',\n",
    "               'other_comorbidities']\n",
    "symptom_list = ['abdominal_pain','altered_smell_taste','anxiety','asthma','asymptomatic','back_pain','blocked_nose',\n",
    "                'blurred_vision','body_aches','chest_pain','chills_or_shivers','cyanosis','delirium','diarrhoea',\n",
    "                'discomfort','dizzy_light_headed','eye_soreness','fatigue_weakness','fever','gastrointestinal_symptoms',\n",
    "                'headache','insomnia','loss_of_appetite','low_o2_sat','myalgia','nausea','other','other_respiratory',\n",
    "                'other_skin','persistent_cough','retro_orbital_pain','runny_nose','seizures','shortness_of_breath',\n",
    "                'skin_lesions','sneezing','sore_throat','unusual_joint_pains']\n",
    "variants_name = ['Delta','BA.1.X','BA.2.X','BA.4/5.X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.read_parquet('df_ML.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = df_encoded.columns[df_encoded.columns.str.contains('state')].tolist()\n",
    "variant_list = df_encoded.columns[df_encoded.columns.str.contains('variant')].tolist()\n",
    "ethnicity_list = df_encoded.columns[df_encoded.columns.str.contains('ethnicity')].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Multivariate Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection for model\n",
    "\n",
    "I exclude icu admission and invasive ventilation from parameters since they are strongly correlated with the final outcome (as logically expected)\n",
    "\n",
    "I drop also noninvasive ventilation and length of stay: features created while hospitalized\n",
    "\n",
    "I work on reducing the number of parameters going into the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I arbitrarly set the minimum number of parameters to go into the fitting to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta\n",
      "Test score:0.709  nb of features: 89\n",
      "Test score:0.708  nb of features: 51\n",
      "Test score:0.702  nb of features: 47\n",
      "Test score:0.703  nb of features: 39\n",
      "Test score:0.703  nb of features: 38\n",
      "BA.1.X\n",
      "Test score:0.703  nb of features: 89\n",
      "Test score:0.703  nb of features: 55\n",
      "BA.2.X\n",
      "Test score:0.765  nb of features: 89\n",
      "Test score:0.763  nb of features: 17\n",
      "Test score:0.763  nb of features: 15\n",
      "BA.4/5.X\n",
      "Test score:0.732  nb of features: 89\n",
      "Test score:0.732  nb of features: 79\n",
      "Test score:0.732  nb of features: 75\n",
      "Test score:0.734  nb of features: 71\n",
      "Test score:0.735  nb of features: 64\n",
      "Test score:0.735  nb of features: 50\n",
      "Test score:0.732  nb of features: 48\n"
     ]
    }
   ],
   "source": [
    "list_features = []\n",
    "for variant in variants_name:\n",
    "    print(variant)\n",
    "    df_variant = df_encoded[df_encoded['variant_'+variant]==1].drop(columns=['age_group','ventilation_invasive','icu_adm','pregnancy','puerperal','ventilation_noninvasive','length_stay']).drop(columns=variant_list)\n",
    "    df_variant_filled = df_variant.dropna(axis=0)\n",
    "    X, y = df_variant_filled.drop(['outcome'],1), df_variant_filled.outcome\n",
    "    scaler = MinMaxScaler()\n",
    "    X[['age','nb_comorbidities','delay_lastdose_onset','length_delay','nb_vaccine_dose']] = scaler.fit_transform(X[['age','nb_comorbidities','delay_lastdose_onset','length_delay','nb_vaccine_dose']])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    logreg = LogisticRegression(solver='newton-cholesky')\n",
    "    selector = RFECV(logreg,step=1,min_features_to_select=15)\n",
    "    check_convergence = 0\n",
    "    init_df = 0\n",
    "    while (check_convergence==0):\n",
    "        if init_df == 0:\n",
    "            X_loop = X_train.copy()\n",
    "            init_df = 1\n",
    "        else:\n",
    "            X_loop = X_train[feature_order[feature_order.ranking==1].feature]\n",
    "        selector = selector.fit(X_loop,y_train)\n",
    "        score = selector.score(X_test[X_loop.columns],y_test)\n",
    "        print(\"Test score:{:.3f}\".format(score),' ',end=\"\")\n",
    "        feature_order = pd.DataFrame()\n",
    "        feature_order['feature'] = X_loop.columns\n",
    "        feature_order['selected'] = selector.support_\n",
    "        feature_order['ranking'] = selector.ranking_\n",
    "        print('nb of features:',len(X_loop.columns))\n",
    "        if len(X_loop.columns) == len(X_train[feature_order[feature_order.ranking==1].feature].columns):\n",
    "            check_convergence = 1\n",
    "            list_features.append(X_train[feature_order[feature_order.ranking==1].feature].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_param_toscale = ['age','nb_comorbidities','delay_lastdose_onset','length_delay','nb_vaccine_dose']\n",
    "for variant in variants_name:\n",
    "    print(variant)\n",
    "    df_variant = df_encoded[df_encoded['variant_'+variant]==1].drop(columns=['age_group','ventilation_invasive','icu_adm','pregnancy','puerperal','ventilation_noninvasive','length_stay']).drop(columns=variant_list)\n",
    "    param_variant = list_features[variants_name.index(variant)].copy()\n",
    "    param_variant.append('outcome')\n",
    "    df_variant = df_variant[param_variant]\n",
    "    df_variant_filled = df_variant.dropna(axis=0)\n",
    "    X, y = df_variant_filled.drop(['outcome'],1), df_variant_filled.outcome\n",
    "    param_toscale = []\n",
    "    for param in list_param_toscale:\n",
    "        if param in df_variant_filled.columns:\n",
    "                param_toscale.append(param)\n",
    "    if len(param_toscale)>0:\n",
    "        scaler = MinMaxScaler()\n",
    "        X[param_toscale] = scaler.fit_transform(X[param_toscale])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "    logm1 = sm.GLM(y_train,(sm.add_constant(X_train)),family = sm.families.Binomial())\n",
    "#    logreg = LogisticRegression(solver='newton-cholesky')\n",
    "    if variant == 'Delta':\n",
    "        res_delta = logm1.fit()\n",
    "    elif variant == 'BA.1.X':\n",
    "        res_ba1x = logm1.fit()\n",
    "    elif variant == 'BA.2.X':\n",
    "        res_ba2x = logm1.fit()\n",
    "    elif variant == 'BA.4/5.X':\n",
    "        res_ba45x = logm1.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ['Delta']:\n",
    "    print(variant)\n",
    "    df_variant = df_encoded[df_encoded['variant_'+variant]==1].drop(columns=['age_group','ventilation_invasive','icu_adm','pregnancy','puerperal','ventilation_noninvasive','length_stay']).drop(columns=variant_list)\n",
    "    param_variant = list_features[variants_name.index(variant)].copy()\n",
    "    param_variant.append('outcome')\n",
    "    df_variant = df_variant[param_variant]\n",
    "    df_variant_filled = df_variant.dropna(axis=0)\n",
    "    X, y = df_variant_filled.drop(['outcome'],1), df_variant_filled.outcome\n",
    "    param_toscale = []\n",
    "    for param in list_param_toscale:\n",
    "        if param in df_variant_filled.columns:\n",
    "                param_toscale.append(param)\n",
    "    if len(param_toscale)>0:\n",
    "        scaler = MinMaxScaler()\n",
    "        X[param_toscale] = scaler.fit_transform(X[param_toscale])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare predicted outcome with observed outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = res_delta.predict(sm.add_constant(X_train))\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x>0.5 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "Visualize algorithm performance\n",
    "\n",
    "\n",
    "|True Negative | False Positive|\n",
    "|-|-|\n",
    "|**False Negative** | **True Positive**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_cm = pd.DataFrame(confusion,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "(TP+TN) / (TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_train_pred_final.Converted,y_train_pred_final.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the algorithm is set, it predicts the outcome for the training set correcly 70% of the time\n",
    "\n",
    "But the is data unbalanced: 66% of cured vs. 34% of dead in the training data.\n",
    "\n",
    "Model predicts correctly death in only **36%** of the cases (recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model optimization\n",
    "#### ROC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC function\n",
    "\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trade off: accuracy, specificity, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [float(x)/10 for x in range(10)]\n",
    "numbers = np.linspace(0,1,21)\n",
    "for i in numbers:\n",
    "    y_train_pred_final['%.2f'%i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "num = np.linspace(0,1,21)\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final['%.2f'%i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation model with new cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "print(confusion2)\n",
    "df_cm = pd.DataFrame(confusion2,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "plt.plot(thresholds, p[:-1], \"b:\")\n",
    "plt.plot(thresholds, r[:-1], \"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut off value near value where precision and recall intersect: keep model as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res_delta.predict(sm.add_constant(X_test))\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.35 else 0)\n",
    "print(metrics.accuracy_score(y_pred_final['outcome'], y_pred_final.final_predicted))\n",
    "confusion3 = metrics.confusion_matrix(y_pred_final['outcome'], y_pred_final.final_predicted )\n",
    "print(confusion3)\n",
    "df_cm = pd.DataFrame(confusion3,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')\n",
    "TP = confusion3[1,1] \n",
    "TN = confusion3[0,0] \n",
    "FP = confusion3[0,1] \n",
    "FN = confusion3[1,0] \n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BA.1.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ['BA.1.X']:\n",
    "    df_variant = df_encoded[df_encoded['variant_'+variant]==1].drop(columns=['age_group','ventilation_invasive','icu_adm','pregnancy','puerperal','ventilation_noninvasive','length_stay']).drop(columns=variant_list)\n",
    "    param_variant = list_features[variants_name.index(variant)].copy()\n",
    "    param_variant.append('outcome')\n",
    "    df_variant = df_variant[param_variant]\n",
    "    df_variant_filled = df_variant.dropna(axis=0)\n",
    "    X, y = df_variant_filled.drop(['outcome'],1), df_variant_filled.outcome\n",
    "    param_toscale = []\n",
    "    for param in list_param_toscale:\n",
    "        if param in df_variant_filled.columns:\n",
    "                param_toscale.append(param)\n",
    "    if len(param_toscale)>0:\n",
    "        scaler = MinMaxScaler()\n",
    "        X[param_toscale] = scaler.fit_transform(X[param_toscale])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "y_train_pred = res_ba1x.predict(sm.add_constant(X_train))\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x>0.5 else 0)\n",
    "#confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\n",
    "print(confusion)\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted,y_train_pred_final.Predicted))\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "numbers = np.linspace(0,1,21)\n",
    "for i in numbers:\n",
    "    y_train_pred_final['%.2f'%i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "num = np.linspace(0,1,21)\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final['%.2f'%i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "print(confusion2)\n",
    "df_cm = pd.DataFrame(confusion2,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "plt.plot(thresholds, p[:-1], \"b:\")\n",
    "plt.plot(thresholds, r[:-1], \"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res_ba1x.predict(sm.add_constant(X_test))\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.35 else 0)\n",
    "print(metrics.accuracy_score(y_pred_final['outcome'], y_pred_final.final_predicted))\n",
    "confusion3 = metrics.confusion_matrix(y_pred_final['outcome'], y_pred_final.final_predicted )\n",
    "print(confusion3)\n",
    "df_cm = pd.DataFrame(confusion3,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')\n",
    "TP = confusion3[1,1] \n",
    "TN = confusion3[0,0] \n",
    "FP = confusion3[0,1] \n",
    "FN = confusion3[1,0] \n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BA.2.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ['BA.2.X']:\n",
    "    df_variant = df_encoded[df_encoded['variant_'+variant]==1].drop(columns=['age_group','ventilation_invasive','icu_adm','pregnancy','puerperal','ventilation_noninvasive','length_stay']).drop(columns=variant_list)\n",
    "    param_variant = list_features[variants_name.index(variant)].copy()\n",
    "    param_variant.append('outcome')\n",
    "    df_variant = df_variant[param_variant]\n",
    "    df_variant_filled = df_variant.dropna(axis=0)\n",
    "    X, y = df_variant_filled.drop(['outcome'],1), df_variant_filled.outcome\n",
    "    param_toscale = []\n",
    "    for param in list_param_toscale:\n",
    "        if param in df_variant_filled.columns:\n",
    "                param_toscale.append(param)\n",
    "    if len(param_toscale)>0:\n",
    "        scaler = MinMaxScaler()\n",
    "        X[param_toscale] = scaler.fit_transform(X[param_toscale])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "y_train_pred = res_ba2x.predict(sm.add_constant(X_train))\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x>0.5 else 0)\n",
    "#confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\n",
    "print(confusion)\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted,y_train_pred_final.Predicted))\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "numbers = np.linspace(0,1,21)\n",
    "for i in numbers:\n",
    "    y_train_pred_final['%.2f'%i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "num = np.linspace(0,1,21)\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final['%.2f'%i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.25 else 0)\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "print(confusion2)\n",
    "df_cm = pd.DataFrame(confusion2,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "plt.plot(thresholds, p[:-1], \"b:\")\n",
    "plt.plot(thresholds, r[:-1], \"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res_ba2x.predict(sm.add_constant(X_test))\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.25 else 0)\n",
    "print(metrics.accuracy_score(y_pred_final['outcome'], y_pred_final.final_predicted))\n",
    "confusion3 = metrics.confusion_matrix(y_pred_final['outcome'], y_pred_final.final_predicted )\n",
    "print(confusion3)\n",
    "df_cm = pd.DataFrame(confusion3,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')\n",
    "TP = confusion3[1,1] \n",
    "TN = confusion3[0,0] \n",
    "FP = confusion3[0,1] \n",
    "FN = confusion3[1,0] \n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BA.4/5.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ['BA.4/5.X']:\n",
    "    df_variant = df_encoded[df_encoded['variant_'+variant]==1].drop(columns=['age_group','ventilation_invasive','icu_adm','pregnancy','puerperal','ventilation_noninvasive','length_stay']).drop(columns=variant_list)\n",
    "    param_variant = list_features[variants_name.index(variant)].copy()\n",
    "    param_variant.append('outcome')\n",
    "    df_variant = df_variant[param_variant]\n",
    "    df_variant_filled = df_variant.dropna(axis=0)\n",
    "    X, y = df_variant_filled.drop(['outcome'],1), df_variant_filled.outcome\n",
    "    param_toscale = []\n",
    "    for param in list_param_toscale:\n",
    "        if param in df_variant_filled.columns:\n",
    "                param_toscale.append(param)\n",
    "    if len(param_toscale)>0:\n",
    "        scaler = MinMaxScaler()\n",
    "        X[param_toscale] = scaler.fit_transform(X[param_toscale])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "y_train_pred = res_ba45x.predict(sm.add_constant(X_train))\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x>0.5 else 0)\n",
    "#confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\n",
    "print(confusion)\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted,y_train_pred_final.Predicted))\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "numbers = np.linspace(0,1,21)\n",
    "for i in numbers:\n",
    "    y_train_pred_final['%.2f'%i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "num = np.linspace(0,1,21)\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final['%.2f'%i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.275 else 0)\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "print(confusion2)\n",
    "df_cm = pd.DataFrame(confusion2,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
    "plt.plot(thresholds, p[:-1], \"b:\")\n",
    "plt.plot(thresholds, r[:-1], \"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res_ba45x.predict(sm.add_constant(X_test))\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.25 else 0)\n",
    "print(metrics.accuracy_score(y_pred_final['outcome'], y_pred_final.final_predicted))\n",
    "confusion3 = metrics.confusion_matrix(y_pred_final['outcome'], y_pred_final.final_predicted )\n",
    "print(confusion3)\n",
    "df_cm = pd.DataFrame(confusion3,index=['Cured (obs)','Dead (obs)'],columns=['Cured (pred)','Dead (pred)'])\n",
    "sns.heatmap(df_cm,annot=True,fmt='4d',cmap='BrBG')\n",
    "TP = confusion3[1,1] \n",
    "TN = confusion3[0,0] \n",
    "FP = confusion3[0,1] \n",
    "FN = confusion3[1,0] \n",
    "#precision\n",
    "print('Precision:',TP/(TP+FP))\n",
    "#recall\n",
    "print('Recall:',TP/(TP+FN))\n",
    "#f-score\n",
    "print('f-score:',((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
